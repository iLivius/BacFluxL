print(r'''
________             _______________             ______       
___  __ )_____ _________  ____/__  /___  _____  ____  / 
__  __  |  __ `/  ___/_  /_   __  /_  / / /_  |/_/_  /
_  /_/ // /_/ // /__ _  __/   _  / / /_/ /__>  < _  /___
/_____/ \__,_/ \___/ /_/      /_/  \__,_/ /_/|_| /_____/
                                                                                                            
BacFluxL v1.1.0 â€” Genomic Analysis of Bacterial ONT Reads


Livio Antonielli, February 2026
''')

# Modules:
import os
import sys
from urllib.parse import urlparse

# Configuration file:
configfile: 'config/config.yaml'

# Path to DBs and input/output directories in config file:
workdir: config['directories']['output_dir']
INPUTDIR = config['directories']['input_dir']
BAKTADB = config['directories']['bakta_db']
BLASTDB = config['directories']['blast_db']
DMNDDB = config['directories']['eggnog_db']
GTDBTKDB = config['directories']['gtdbtk_db']
PLATONDB = config['directories']['platon_db']

# AMR DBs (ABRicate):
DATABASES = ["argannot", "card", "ecoh", "ecoli_vf", "megares", "ncbi", "resfinder", "vfdb"]

# Hardware resources in config file:
CPUS = config['resources']['threads']

# Sanity check of genus parameter:
if config['parameters'] is not None and "genus" in config['parameters']:
    genus = config['parameters']["genus"]
    if genus is not None and len(genus) > 0:
        print(f"The 'genus' parameter is specified in the config file with value: '{genus}'.")
    else:
        print("The 'genus' parameter value is not specified in the config file and will be inferred automatically.")
else:
    print("The 'genus' parameter is not present in the config file.")

# Sanity check of Medaka parameter:
input_mode = None

params = config.get("parameters", {})
model  = params.get("medaka_model", None)

def _is_false(v):
    if isinstance(v, bool): return v is False
    if v is None: return False
    return str(v).strip().lower() in {"false","0","no","off"}

def _is_empty(v):
    return v is None or (isinstance(v, str) and v.strip() == "")

if _is_false(model):
    print("Medaka disabled via config. Skipping consensus polishing.")
    input_mode = "--nano-hq"
elif isinstance(model, str) and model.strip():
    print(f"The 'model' parameter of Medaka is specified with value: '{model}'.")
    input_mode = "--nano-raw" if "fast" in model else "--nano-hq"
else:
    # True / missing / empty string => infer model later in the medaka rule
    print("Medaka model will be inferred automatically from FASTQ headers.")
    input_mode = "--nano-hq"

# Function to determine final contigs path based on Medaka parameter
def final_contigs(wc):
    # medaka_model empty/False => skip
    m = str(config["parameters"].get("medaka_model", "")).strip().lower()
    use_medaka = (m not in ["", "false", "none", "0", "no"])
    if use_medaka:
        return f"03.post-processing/consensus/{wc.sample}/consensus.fasta"
    else:
        return f"03.post-processing/contaminants/{wc.sample}/assembly_decontam.fasta"

# Sanity check of checkv db link parameter:
global id
id = None

if config['links'] is not None and "checkv_link" in config['links']:
    link = config['links']["checkv_link"]
    if link is not None and len(link) > 0:
        path = urlparse(link).path
        db = os.path.basename(path)
        id = os.path.splitext(os.path.splitext(db)[0])[0]
    else:
        print("The link to CheckV database is not specified and the latest version will be automatically downloaded.")
else:
    sys.stderr.write(f"The checkv_link parameter is not present. Please, check the config file.\n")
    sys.exit(0)

# Import FASTQ files from ONT input dir
SAMPLES, EXTENSIONS = glob_wildcards(os.path.join(INPUTDIR, '{sample}_ont.{extn}'))

if SAMPLES:
    for sample in sorted(SAMPLES):
        print(f"Sample {sample} will be processed.")
else:
    sys.stderr.write(f"No files in {INPUTDIR}. Please, check the directory.\n")
    sys.exit(0)

# Check if ONT files have nonunique extension:
if EXTENSIONS:
    for extension in EXTENSIONS:
        if extension.endswith(("fastq", "fq", "fastq.gz", "fq.gz")):
            if len(set(EXTENSIONS)) != 1:
                sys.stderr.write("More than one type of file extension detected\n\t")
                sys.stderr.write("\n\t".join(set(EXTENSIONS)))
                sys.exit(0)
        else:
            sys.stderr.write("\nFile format not recognized.\n")
            sys.exit(0)
else:
    sys.stderr.write("No suitable file extension found.\n")
    sys.exit(0)

# Create sample objects:
EXTN = EXTENSIONS[0]
ONT = '{sample}_ont.' + EXTN

rule all:
  input:
    filt_long = expand("01.pre-processing/{sample}_filt.fastq", sample = SAMPLES),
    nanoplot_raw_dir  = expand("01.pre-processing/read_qc/{sample}/raw_read_qc", sample = SAMPLES),
    nanoplot_filt_dir = expand("01.pre-processing/read_qc/{sample}/filt_read_qc", sample = SAMPLES),
    flye_dir = expand("02.assembly/{sample}", sample = SAMPLES),
    flye_contigs = expand("02.assembly/{sample}/assembly.fasta", sample = SAMPLES),
    flye_info = expand("02.assembly/{sample}/assembly_info.txt", sample = SAMPLES),
    ignore_list = expand("02.assembly/{sample}/ignore_list.txt", sample = SAMPLES),
    dnaapler_dir = expand("03.post-processing/fix_start/{sample}", sample = SAMPLES),
    dnaapler_contigs = expand("03.post-processing/fix_start/{sample}/{sample}_reoriented.fasta", sample = SAMPLES),
    fixed_contigs = expand("03.post-processing/fix_start/{sample}/{sample}_fixed.fasta", sample = SAMPLES),
    qualimap_dir = expand("03.post-processing/mapping_evaluation/{sample}", sample = SAMPLES),
    bestscore = expand("03.post-processing/contaminants/{sample}/bestscore.blob.blobDB.table.txt", sample = SAMPLES),
    abund = expand("03.post-processing/contaminants/{sample}/{sample}_composition.txt", sample = SAMPLES),
    list = expand("03.post-processing/contaminants/{sample}/contigs.list", sample = SAMPLES),
    decontam_contigs = expand("03.post-processing/contaminants/{sample}/assembly_decontam.fasta", sample = SAMPLES),
    checkm_stats = expand("03.post-processing/completeness_evaluation/{sample}/checkm_stats.tsv", sample = SAMPLES),
    checkm_lineage = expand("03.post-processing/completeness_evaluation/{sample}/lineage.ms", sample = SAMPLES),
    gtdbtk_dir = expand("04.taxonomy/{sample}", sample = SAMPLES),
    bakta_dir = expand("05.annotation/bakta/{sample}", sample = SAMPLES),
    eggnog_dir = expand("05.annotation/eggnog/{sample}", sample = SAMPLES),
    antismash_dir = expand("05.annotation/antismash/{sample}", sample = SAMPLES),
    dbcan_db = "05.annotation/dbcan/dbcan_db_v5.1.2",
    dbcan_dir = expand("05.annotation/dbcan/{sample}", sample = SAMPLES),
    amr_tab = expand("06.AMR/ABRicate/{sample}/{db}.tsv", sample = SAMPLES, db = DATABASES),
    amr_summary = expand("06.AMR/ABRicate/{sample}/AMR_summary.txt", sample = SAMPLES),
    plasmid_dir = expand("07.plasmids/{sample}", sample = SAMPLES),
    plasmids = expand("07.plasmids/{sample}/verified_plasmids.txt", sample = SAMPLES),
    vs2_dir = expand("08.phages/virsorter/{sample}", sample = SAMPLES),
    checkv_dir = expand("08.phages/checkv/{sample}", sample = SAMPLES),
    multiqc_dir = "09.report"

rule filter_reads:
  input:
    long = os.path.join(INPUTDIR, ONT),
  output:
    filt_long = "01.pre-processing/{sample}_filt.fastq"
  params:
    min_length = 1000,
    keep_percent = 90,
    target_bases = 500000000
  conda:
    "envs/filtlong.yaml"
  message:
    "--- Filtlong: Filter long reads. ---"
  log:
    "logs/filter_reads_{sample}.log"
  shell:
    """
    filtlong \
      --min_length {params.min_length} \
      --keep_percent {params.keep_percent} \
      --target_bases {params.target_bases} \
      {input.long} > {output.filt_long} 2>{log}
    """

rule raw_read_qc:
  input:
    fastq = os.path.join(INPUTDIR, ONT)
  output:
    nanoplot_raw_dir = directory("01.pre-processing/read_qc/{sample}/raw_read_qc")
  resources:
    cpus = min(CPUS, 8)
  conda:
    "envs/nanoplot.yaml"
  log:
    "logs/raw_read_qc_{sample}.log"
  shell:
    """
    NanoPlot \
      --fastq {input.fastq} \
      --threads {resources.cpus} \
      --loglength \
      --prefix "{wildcards.sample}_" \
      --outdir {output.nanoplot_raw_dir} > {log} 2>&1
    """

rule filtered_read_qc:
  input:
    fastq = "01.pre-processing/{sample}_filt.fastq"
  output:
    nanoplot_filt_dir = directory("01.pre-processing/read_qc/{sample}/filt_read_qc")
  resources:
    cpus = min(CPUS, 8)
  conda:
    "envs/nanoplot.yaml"
  log:
    "logs/filtered_read_qc_{sample}.log"
  shell:
    """
    NanoPlot \
      --fastq {input.fastq} \
      --threads {resources.cpus} \
      --loglength \
      --prefix "{wildcards.sample}_" \
      --outdir {output.nanoplot_filt_dir} > {log} 2>&1
    """

# AWK command to build ignore contig list from Flye assembly_info.txt
IGNORE_LIST_CMD = r"""BEGIN{FS="[[:space:]]+"} NR>1 && $4!="Y" {print $1}"""

rule assembly:
  input:
    filt_long = "01.pre-processing/{sample}_filt.fastq"
  output:
    flye_dir = directory("02.assembly/{sample}"),
    flye_contigs = "02.assembly/{sample}/assembly.fasta", 
    flye_info = "02.assembly/{sample}/assembly_info.txt",
    ignore_list = "02.assembly/{sample}/ignore_list.txt"
  params:
    input_mode = input_mode,
    iterations = 5
  resources:
    cpus = CPUS
  conda:
    "envs/flye.yaml"
  message:
    "--- Flye: Genome assembly with long reads. ---"
  log:
    "logs/genome_assembly_{sample}.log"
  shell:
    """
    flye \
      {params.input_mode} \
      {input.filt_long} \
      --out-dir {output.flye_dir} \
      --threads {resources.cpus} \
      --iterations {params.iterations} > {log} 2>&1

    # Build ignore list from Flye assembly_info.txt (look for non-circular contigs)
    awk {IGNORE_LIST_CMD:q} {output.flye_info} > {output.ignore_list}
    """

# AWK command to simplify FASTA headers (keep only first word after '>')
FASTA_HEAD_CMD = r"""BEGIN{FS=" "} /^>/{print $1; next} {print}"""

# AWK command to linearize FASTA sequences
FASTA_LIN_CMD  = r"""{if(NR==1) {printf "%s\n", $0} else {if(/^>/) {printf "\n%s\n", $0} else {printf $0}}}"""

rule fix_start:
  input:
    flye_contigs = "02.assembly/{sample}/assembly.fasta",
    ignore_list = "02.assembly/{sample}/ignore_list.txt"
  output:
    dnaapler_dir = directory("03.post-processing/fix_start/{sample}"),
    dnaapler_contigs = "03.post-processing/fix_start/{sample}/{sample}_reoriented.fasta",
    fixed_contigs = "03.post-processing/fix_start/{sample}/{sample}_fixed.fasta"
  params:
    evalue = 1e-10,
    seed = 42
  resources:
    cpus = min(CPUS, 24)
  conda: "envs/dnaapler.yaml"
  log: "logs/fix_start_{sample}.log"
  shell:
    """
    dnaapler all \
      -i {input.flye_contigs} \
      -p {wildcards.sample} \
      -e {params.evalue} \
      --seed_value {params.seed} \
      -t {resources.cpus} \
      -o {output.dnaapler_dir} \
      --ignore {input.ignore_list} \
      --force > {log} 2>&1

    # Simplify headers and linearize
    awk {FASTA_HEAD_CMD:q} {output.dnaapler_contigs} | \
    awk {FASTA_LIN_CMD:q} > {output.fixed_contigs}
    """

rule map_contigs:
  input:
    filt_long = "01.pre-processing/{sample}_filt.fastq",
    fixed_contigs = "03.post-processing/fix_start/{sample}/{sample}_fixed.fasta",
  output:
    bam = temp("03.post-processing/contaminants/{sample}_map.bam"),
    bai = temp("03.post-processing/contaminants/{sample}_map.bam.bai")
  resources:
    cpus = CPUS
  conda:
    "envs/minimap.yaml"
  message:
    "--- Minimap2: Map reads against contigs. ---"
  log:
    "logs/map_contigs_{sample}.log"
  priority: 0
  shell:
    """
    minimap2 \
      -ax map-ont {input.fixed_contigs} \
      {input.filt_long} 2> {log} | \
    samtools view \
      -S \
      -b \
      -u \
      -@ {resources.cpus} | \
    samtools sort \
      -o {output.bam} \
      -@ {resources.cpus} 2>> {log}
    
    samtools index \
      {output.bam} \
      -@ {resources.cpus} 2>> {log}
    """

rule map_qc:
  input:
    bam = "03.post-processing/contaminants/{sample}_map.bam"
  output:
    qualimap_dir = directory("03.post-processing/mapping_evaluation/{sample}")
  resources:
    java_mem = 24,
    threads = min(CPUS, 24)
  conda:
    "envs/qualimap.yaml"
  log:
    "logs/map_qc_{sample}.log"
  shell:
    """
    qualimap bamqc \
      -bam {input.bam} \
      --java-mem-size={resources.java_mem}G \
      -nt {resources.threads} \
      -outdir {output.qualimap_dir} \
      -outformat html > {log} 2>&1
    """

rule blast_contigs:
  input:
    fixed_contigs = "03.post-processing/fix_start/{sample}/{sample}_fixed.fasta"
  output:
    blast = "03.post-processing/contaminants/{sample}/blastout"
  params:
    dir = BLASTDB,
    db = os.path.join(BLASTDB, config['parameters']['nt_version'])
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/blast.yaml"
  message:
    "--- BLAST: Align contigs against NCBI nt db. ---"
  log:
    "logs/blast_contigs_{sample}.log"
  priority: 0
  shell:
    """
    BLASTDB={params.dir} \
    blastn \
      -task megablast \
      -query {input.fixed_contigs} \
      -db {params.db} \
      -outfmt '6 qseqid staxids bitscore pident evalue length qlen slen qcovs qcovhsp sskingdoms scomnames sscinames sblastnames stitle' \
      -num_threads {resources.cpus} \
      -evalue 1e-5 \
      -max_target_seqs 50 \
      -max_hsps 5 \
      -out {output.blast} > {log} 2>&1
    """

rule blob_json:
  input:
    fixed_contigs = "03.post-processing/fix_start/{sample}/{sample}_fixed.fasta",
    bam = "03.post-processing/contaminants/{sample}_map.bam",
    bai = "03.post-processing/contaminants/{sample}_map.bam.bai",
    blast = "03.post-processing/contaminants/{sample}/blastout",
    nodes = os.path.join(BLASTDB, "nodes.dmp"),
    names = os.path.join(BLASTDB, "names.dmp")
  output:
    json = temp("03.post-processing/contaminants/{sample}/blob.blobDB.json"),
    cov = temp("03.post-processing/contaminants/{sample}/blob.{sample}_map.bam.cov")
  params:
    basename = "03.post-processing/contaminants/{sample}/blob"
  conda:
    "envs/blobtools.yaml"
  message:
    "--- BlobTools: Screen BLAST hits for contaminants. ---"
  log:
    "logs/blob_json_{sample}.log"
  priority: 0
  shell:
    """
    blobtools create \
      -i {input.fixed_contigs} \
      -b {input.bam} \
      -t {input.blast} \
      --nodes {input.nodes} \
      --names {input.names} \
      -o {params.basename} > {log} 2>&1
    """

rule blob_table:
  input:
    json = "03.post-processing/contaminants/{sample}/blob.blobDB.json"
  output:
    bestscore = "03.post-processing/contaminants/{sample}/bestscore.blob.blobDB.table.txt"
  params:
    basename = "03.post-processing/contaminants/{sample}/bestscore"
  conda:
    "envs/blobtools.yaml"
  message:
    "--- BlobTools: Collapse taxonomic assignment of BLAST hits according to sum of best scores. ---"
  log:
    "logs/blob_table_{sample}.log"
  priority: 0
  shell:
    """
    blobtools view \
      --input {input.json} \
      --out {params.basename} \
      --taxrule bestsum \
      --rank all \
      --hits > {log} 2>&1
    """
  
# Execute either one rule or another according to presence/absence of 'genus' parameter
if "genus" in config['parameters'] and config['parameters']['genus'] is not None and len(config['parameters']['genus']) > 0:
  rule:
    input:
      bestscore = "03.post-processing/contaminants/{sample}/bestscore.blob.blobDB.table.txt",
      fixed_contigs = "03.post-processing/fix_start/{sample}/{sample}_fixed.fasta"
    output:
      abund = "03.post-processing/contaminants/{sample}/{sample}_composition.txt",
      list = "03.post-processing/contaminants/{sample}/contigs.list",
      decontam_contigs = "03.post-processing/contaminants/{sample}/assembly_decontam.fasta"
    params:
      genus = config['parameters']['genus']    
    priority: 0
    shell:
      """
      for i in $(cat {input.bestscore} | sed '1,11d' | cut -f 22 | sort -u); do \
        cat {input.bestscore} | sed '1,11d' | awk -v var=$i 'BEGIN {{printf "%s%s", var, ": "}} $22 == var {{count++}} END {{printf "%.2f\\n", count/NR}}'; \
      done > {output.abund}

      echo "Sample {wildcards.sample} composition:"
      cat {output.abund}
      
      awk -v var="{params.genus}" 'tolower($22) ~ tolower("[:alpha:]*"var) {{print $1}}' {input.bestscore} > {output.list}
      
      grep -A1 -f {output.list} {input.fixed_contigs} | sed '/--/d' > {output.decontam_contigs}
      """
else:
  rule:
    input:
      bestscore = "03.post-processing/contaminants/{sample}/bestscore.blob.blobDB.table.txt",
      fixed_contigs = "03.post-processing/fix_start/{sample}/{sample}_fixed.fasta"
    output:
      abund = "03.post-processing/contaminants/{sample}/{sample}_composition.txt",
      list = "03.post-processing/contaminants/{sample}/contigs.list",
      decontam_contigs = "03.post-processing/contaminants/{sample}/assembly_decontam.fasta"
    priority: 0
    shell:
      """
      for i in $(cat {input.bestscore} | sed '1,11d' | cut -f 22 | sort -u); do \
        cat {input.bestscore} | sed '1,11d' | awk -v var=$i 'BEGIN {{printf "%s%s", var, ": "}} $22 == var {{count++}} END {{printf "%.2f\\n", count/NR}}'; \
      done > {output.abund}

      echo "Sample {wildcards.sample} composition:"
      cat {output.abund}

      for i in $(cat {output.abund} | sort -t':' -k2 -nr | cut -d':' -f1 | sed -n '1p' | sed -e 's/Para//;s/Pseudo//;s/Paen//' | tr '[:upper:]' '[:lower:]'); do \
        awk -v var="$i" 'tolower($22) ~ tolower("[:alpha:]*"var) {{print $1}}' {input.bestscore}; \
      done > {output.list}

      grep -A1 -f {output.list} {input.fixed_contigs} | sed '/--/d' > {output.decontam_contigs}
      """

# Conditional rule execution according to presence/absence of 'medaka_model' parameter
if (
    "medaka_model" in config.get("parameters", {})
    and not isinstance(config["parameters"]["medaka_model"], bool)
    and config["parameters"]["medaka_model"] is not None
    and str(config["parameters"]["medaka_model"]).strip().lower()
        not in {"", "false", "no", "0", "off"}
):
  rule:
    input:
      filt_long = "01.pre-processing/{sample}_filt.fastq",
      decontam_contigs = "03.post-processing/contaminants/{sample}/assembly_decontam.fasta"
    output:
      consensus_dir = directory("03.post-processing/consensus/{sample}"),
      consensus_contigs = "03.post-processing/consensus/{sample}/consensus.fasta"
    params:
      model = config['parameters']['medaka_model'] 
    resources:
      cpus = min(CPUS, 24)
    conda:
      "envs/medaka.yaml"
    message:
      "--- Medaka: Improve contig consensus with long reads. ---"
    log:
      "logs/consensus_long_{sample}.log"
    shell:
      """
      medaka_consensus \
        -i {input.filt_long} \
        -d {input.decontam_contigs} \
        -t {resources.cpus} \
        -m {params.model} \
        -o {output.consensus_dir} > {log} 2>&1
      """
else:
  rule:
    input:
      filt_long = "01.pre-processing/{sample}_filt.fastq",
      decontam_contigs = "03.post-processing/contaminants/{sample}/assembly_decontam.fasta"
    output:
      consensus_dir = directory("03.post-processing/consensus/{sample}"),
      consensus_contigs = "03.post-processing/consensus/{sample}/consensus.fasta"
    resources:
      cpus = min(CPUS, 24)
    conda:
      "envs/medaka.yaml"
    message:
      "--- Medaka: Improve contig consensus with long reads. ---"
    log:
      "logs/consensus_long_{sample}.log"
    shell:
      """
      # Display model automatic inference output
      medaka tools \
        resolve_model \
        --auto_model consensus_bacteria \
        {input.filt_long}

      # Run medaka with inferred model
        -i {input.filt_long} \
        -d {input.decontam_contigs} \
        -t {resources.cpus} \
        -m $(medaka tools resolve_model --auto_model consensus_bacteria {input.filt_long}) \
        -o {output.consensus_dir} > {log} 2>&1
      """

rule finalize_contigs:
  input:
    contigs = final_contigs #helper function if Medaka is skipped
  output:
    final = "03.post-processing/final/{sample}/assembly_final.fasta"
  log:
    "logs/finalize_contigs_{sample}.log"
  shell:
    """
    mkdir -p $(dirname {output.final})

    echo "Final contigs source: {input.contigs}" | tee {log}
    
    cp {input.contigs} {output.final}
    """

rule completeness_and_contamination:
  input:
    final_contigs = "03.post-processing/final/{sample}/assembly_final.fasta"
  output:
    checkm_dir = directory("03.post-processing/completeness_evaluation/{sample}"),
    checkm_stats = "03.post-processing/completeness_evaluation/{sample}/checkm_stats.tsv",
    checkm_lineage = "03.post-processing/completeness_evaluation/{sample}/lineage.ms"
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/checkm.yaml"
  message:
    "--- CheckM: Assessment of genome completenness and contamination. ---"
  log:
    "logs/completenness_and_contamination_{sample}.log"
  priority: 0
  shell:
    """
    cp {input.final_contigs} {output.checkm_dir}/{wildcards.sample}.fasta
    
    checkm lineage_wf \
      -t {resources.cpus} \
      -x fasta {output.checkm_dir} \
      {output.checkm_dir} > {log} 2>&1
    
    checkm qa \
      -o 2 \
      -t {resources.cpus} \
      --tab_table \
      -f {output.checkm_stats} {output.checkm_lineage} {output.checkm_dir} >> {log} 2>&1
    """

rule taxonomic_assignment:
  input:
    checkm_dir = "03.post-processing/completeness_evaluation/{sample}",
  output:
    gtdbtk_dir = directory("04.taxonomy/{sample}")
  params:
    gtdbtk_db = GTDBTKDB,
    skani_sketch_dir = f"{GTDBTKDB}/skani_sketches_r226_skani0.3.1"
  resources:
    cpus = min(CPUS, 24),
    cpus_p = min(CPUS, 24)
  conda:
    "envs/gtdbtk.yaml"
  message:
    "--- GTDB-Tk: Taxonomic assignment. ---"
  log:
    "logs/taxonomic_assignment_{sample}.log"
  priority: 0
  shell:
    """
    mkdir -p {output.gtdbtk_dir} {params.skani_sketch_dir}

    GTDBTK_DATA_PATH={params.gtdbtk_db:q} \
    gtdbtk classify_wf \
      -x fasta \
      --genome_dir {input.checkm_dir} \
      --out_dir {output.gtdbtk_dir} \
      --skani_sketch_dir {params.skani_sketch_dir:q} \
      --cpus {resources.cpus} \
      --pplacer_cpus {resources.cpus_p} > {log} 2>&1

    rm -rf {input.checkm_dir}/*.fasta
    """

rule annotation:
  input:
    final_contigs = "03.post-processing/final/{sample}/assembly_final.fasta",
    abund = "03.post-processing/contaminants/{sample}/{sample}_composition.txt"
  output:
    bakta_dir = directory("05.annotation/bakta/{sample}")
  params:
    bakta_db = BAKTADB
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/bakta.yaml"
  message:
    "--- Bakta: Genome annotation. ---"
  log:
    "logs/annotation_{sample}.log"
  priority: 0
  shell:
    """
    for i in $(cat {input.abund} | sort -t':' -k2 -nr | cut -d':' -f1 | sed -n '1p'); do \
      bakta \
        --db {params.bakta_db} \
        --verbose \
        --genus $i \
        --species sp. \
        --strain {wildcards.sample} \
        --translation-table 11 \
        --min-contig-length 500 \
        --locus-tag {wildcards.sample} \
        --prefix {wildcards.sample} \
        --keep-contig-headers \
        --output {output.bakta_dir} \
        --threads {resources.cpus} \
        --force {input.final_contigs}; \
    done > {log} 2>&1
    """    

rule functional_annotation:
  input:
    bakta_dir = "05.annotation/bakta/{sample}"
  output:
    temp_dir = temp(directory("05.annotation/eggnog/{sample}/eggnog_tmp")),
    eggnog_dir = directory("05.annotation/eggnog/{sample}")
  params:
    dmnd_db = DMNDDB
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/eggnog-mapper.yaml"
  message:
    "--- EggNOG: Functional annotation. ---"
  log:
    "logs/functional_annotation_{sample}.log"
  priority: 0
  shell:
    """
    mkdir -p {output.temp_dir} {output.eggnog_dir}

    emapper.py \
      -i {input.bakta_dir}/{wildcards.sample}.faa \
      --output_dir {output.eggnog_dir} \
      --cpu {resources.cpus} \
      -m diamond \
      --data_dir {params.dmnd_db} \
      --output {wildcards.sample} \
      --temp_dir {output.temp_dir} \
      --override > {log} 2>&1
    """

rule secondary_metabolites_db:
  output:
    antismash_db = directory("05.annotation/antismash/databases")
  conda:
    "envs/antismash.yaml"
  message:
    "--- antiSMASH: database download. ---"
  log:
    "logs/secondary_metabolites_database.log"
  priority: 4
  shell:
    """
    download-antismash-databases \
      --database-dir {output.antismash_db} > {log} 2>&1
    """    

rule secondary_metabolites_analysis:
  input:
    antismash_db = "05.annotation/antismash/databases",
    bakta_dir = "05.annotation/bakta/{sample}"
  output:
    antismash_dir = directory("05.annotation/antismash/{sample}")
  params:
    taxon = 'bacteria',
    genefinding_tool = 'none'
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/antismash.yaml"
  message:
    "--- antiSMASH: secondary metabolite annotation. ---"
  log:
    "logs/secondary_metabolites_{sample}.log"
  priority: 4
  shell:
    """
    antismash \
      --output-dir {output.antismash_dir} \
      --output-basename {wildcards.sample} \
      --databases {input.antismash_db} \
      --taxon {params.taxon} \
      --genefinding-tool {params.genefinding_tool} \
      --cpus {resources.cpus} \
      {input.bakta_dir}/{wildcards.sample}.gbff > {log} 2>&1
    """    

# Specify directory where to place the dbCAN database
DBCAN_DB_DIR = "05.annotation/dbcan/dbcan_db_v5.1.2"

# Sentinel file for triggering the cazyme annotation rule afterwards
DBCAN_SENTINEL = DBCAN_DB_DIR + "/.verified.sha256"

rule cazyme_db_download:
  output:
    dbcan_db = directory("05.annotation/dbcan/dbcan_db_v5.1.2"),
    dbcan_verified = DBCAN_SENTINEL
  params:
    dbcan_db_url = config["links"]["dbcan_link"],
    sha_url = lambda wc: config["links"]["dbcan_link"].replace(".tar.gz", ".sha256")
  log:
    "logs/cazyme_db_download.log"
  priority: 4
  shell:
    """
    mkdir -p "{output.dbcan_db}"

    TAR="{output.dbcan_db}/$(basename "{params.dbcan_db_url}")"
    SHA="{output.dbcan_db}/$(basename "{params.sha_url}")"

    wget -O "$TAR" "{params.dbcan_db_url}" > "{log}" 2>&1
    wget -O "$SHA" "{params.sha_url}" >> "{log}" 2>&1

    # verify checksum
    expected="$(awk 'NR==1{{print $1}}' "$SHA")"
    actual="$(sha256sum "$TAR" | awk '{{print $1}}')"
    test "$expected" = "$actual"

    # extract (flatten top-level directory)
    tar -xzf "$TAR" -C "{output.dbcan_db}" --strip-components=1 >> "{log}" 2>&1

    # create sentinel containing verified checksum
    echo "$actual" > "{output.dbcan_verified}"
    """

rule cazyme_gene_cluster:
  input:
    bakta_dir = "05.annotation/bakta/{sample}",
    dbcan_verified = DBCAN_SENTINEL
  output:
    dbcan_dir = directory("05.annotation/dbcan/{sample}")
  params:
    dbcan_db = DBCAN_DB_DIR
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/dbcan.yaml"
  message:
    "--- dbCAN: Finding CAZyme gene clusters. ---"
  log:
    "logs/cazyme_{sample}.log"
  priority: 4
  shell:
    """
    # CAZyme annotation of protein sequences
    run_dbcan CAZyme_annotation \
      --input_raw_data {input.bakta_dir}/{wildcards.sample}.faa \
      --output_dir {output.dbcan_dir} \
      --db_dir {params.dbcan_db} \
      --mode protein \
      --threads {resources.cpus} \
      --methods hmm \
      --methods diamond \
      --methods dbCANsub > {log} 2>&1

    # CAZyme Gene Cluster (CGC) Annotation
    run_dbcan gff_process \
      --input_gff {input.bakta_dir}/{wildcards.sample}.gff3 \
      --output_dir {output.dbcan_dir} \
      --db_dir {params.dbcan_db} \
      --gff_type prodigal \
      --threads {resources.cpus} >> {log} 2>&1

    # CAZyme Gene Cluster (CGC) Identification
    run_dbcan cgc_finder \
      --output_dir {output.dbcan_dir} >> {log} 2>&1 

    # CGC Substrate Prediction
    run_dbcan substrate_prediction \
      --output_dir {output.dbcan_dir} \
      --db_dir {params.dbcan_db} >> {log} 2>&1
    """

for sample in SAMPLES:
  for db in DATABASES:
    rule:
      input:
        final_contigs = expand("03.post-processing/final/{sample}/assembly_final.fasta", sample = sample)
      output:
        amr_tab = expand("06.AMR/ABRicate/{sample}/{db}.tsv", sample = sample, db = db)
      params:
        db = db,
        minid = 80,
        mincov = 70
      conda:
        "envs/abricate.yaml"
      message:
        "--- ABRicate: AMR detection. ---"
      log:
        expand("logs/amr_{db}_in_{sample}_contigs.log", sample = sample, db = db)
      priority: 4
      shell:
        """
        abricate \
          --db {params.db} \
          {input.final_contigs} \
          --minid {params.minid} \
          --mincov {params.mincov} \
          --nopath \
          --quiet > {output.amr_tab} 2> {log}
        """
 
rule AMR_summary:
  input:
    argannot = "06.AMR/ABRicate/{sample}/argannot.tsv",
    card = "06.AMR/ABRicate/{sample}/card.tsv",
    ecoh = "06.AMR/ABRicate/{sample}/ecoh.tsv",
    ecoli_vf = "06.AMR/ABRicate/{sample}/ecoli_vf.tsv",
    megares = "06.AMR/ABRicate/{sample}/megares.tsv",
    ncbi = "06.AMR/ABRicate/{sample}/ncbi.tsv",
    resfinder = "06.AMR/ABRicate/{sample}/resfinder.tsv",
    vfdb = "06.AMR/ABRicate/{sample}/vfdb.tsv"
  output:
    amr_summary = "06.AMR/ABRicate/{sample}/AMR_summary.txt"
  conda:
    "envs/abricate.yaml"
  shell:
    """
    abricate --summary \
      {input.argannot} \
      {input.card} \
      {input.ecoh} \
      {input.ecoli_vf} \
      {input.megares} \
      {input.ncbi} \
      {input.resfinder} \
      {input.vfdb} > {output.amr_summary}
    """

rule plasmid_search:
  input:
    final_contigs = "03.post-processing/final/{sample}/assembly_final.fasta",
    blast = "03.post-processing/contaminants/{sample}/blastout"
  output:
    plasmid_dir = directory("07.plasmids/{sample}"),
    plasmids = "07.plasmids/{sample}/verified_plasmids.txt"
  params:
    platon_db = PLATONDB
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/platon.yaml"
  message:
    "--- Platon: Plasmid identification. ---"
  log:
    "logs/plasmid_search_{sample}.log"
  priority: 0
  shell:
    """
    set -euo pipefail

    mkdir -p "{output.plasmid_dir}"

    # Run platon, but don't fail the rule if it exits non-zero
    set +e
    platon \
      --db {params.platon_db} \
      --output {output.plasmid_dir} \
      --verbose \
      --threads {resources.cpus} \
      {input.final_contigs} > {log} 2>&1
    platon_rc=$?
    set -e

    # Safe: find returns 0 even if it finds nothing
    plasmid_fa=$(find "{output.plasmid_dir}" -maxdepth 1 -type f -name "*.plasmid.fasta" -print -quit)

    # Start fresh output file each run
    : > "{output.plasmids}"

    if [[ -n "$plasmid_fa" ]] && [[ -s "$plasmid_fa" ]] && grep -q "^>" "$plasmid_fa"; then
      while IFS= read -r contig; do
        if grep -m 1 -F "$contig" "{input.blast}" | grep -qi "plasmid"; then
          echo "{wildcards.sample}: $contig is a plasmid." >> "{output.plasmids}"
        else
          echo "{wildcards.sample}: $contig was not verified by BLAST search." >> "{output.plasmids}"
        fi
      done < <(awk '/^>/{{sub(/^>/,""); print $1}}' "$plasmid_fa")
    else
      if [[ "$platon_rc" -ne 0 ]]; then
        echo "Platon returned exit code $platon_rc for sample {wildcards.sample}. No plasmids reported (often due to contigs excluded by size filters / finished genomes)." >> "{output.plasmids}"
      else
        echo "Platon found no plasmid in sample {wildcards.sample}." >> "{output.plasmids}"
      fi
    fi
    """

rule viral_db:
  output:
    vs2_db = directory("08.phages/vs2_db"),
    checkv_db = directory("08.phages/checkv_db")
  resources:
    cpus = min(CPUS, 8)
  conda:
    "envs/virsorter.yaml"
  params:
    checkv_link = config['links']['checkv_link'] if 'checkv_link' in config['links'] else None,
    tries = 5,
    db_id = id
  message:
    """
    --- Download VirSort2 database ---
    --- Download CheckV database ---
    """
  log:
    "logs/viral_databases.log"
  priority: 9
  shell:
    """
    virsorter setup -d {output.vs2_db} -j {resources.cpus} > {log} 2>&1
    if [ -z "{params.checkv_link}" ]; then
      checkv download_database \
        {output.checkv_db} >> {log} 2>&1
    else
      wget --tries={params.tries} -c {params.checkv_link} -P {output.checkv_db} >> {log} 2>&1
      tar -xzvf {output.checkv_db}/{params.db_id}.tar.gz -C {output.checkv_db} >> {log} 2>&1
      diamond makedb \
        --in {output.checkv_db}/{params.db_id}/genome_db/checkv_reps.faa \
        --db {output.checkv_db}/{params.db_id}/genome_db/checkv_reps >> {log} 2>&1
    fi
    """

rule viral_identification:
  input:
    final_contigs = "03.post-processing/final/{sample}/assembly_final.fasta",
    vs2_db = "08.phages/vs2_db",
    checkv_db = "08.phages/checkv_db"
  output:
    vs2_dir = directory("08.phages/virsorter/{sample}"),
    checkv_dir = directory("08.phages/checkv/{sample}")
  params:
    viral_groups = "dsDNAphage,NCLDV,RNA,ssDNA,lavidaviridae",
    min_score = 0.5,
    checkv_link = config['links']['checkv_link'] if 'checkv_link' in config['links'] else None,
    db_id = id
  resources:
    cpus = min(CPUS, 24)
  conda:
    "envs/virsorter.yaml"
  message:
    """
    --- VirSorter2: Identification of phages and prophages. ---
    --- CheckV: Quality assessment of viral genomes. ---
    """
  log:
    "logs/viral_identification_{sample}.log"
  priority: 8
  shell:
    """
    virsorter run  \
      -i {input.final_contigs} \
      -w {output.vs2_dir} \
      -d {input.vs2_db} \
      --keep-original-seq \
      --include-groups {params.viral_groups} \
      --min-score {params.min_score} \
      -j {resources.cpus} \
      all > {log} 2>&1

    if [ -z "{params.checkv_link}" ]; then
      checkv end_to_end \
        {output.vs2_dir}/final-viral-combined.fa {output.checkv_dir} \
        -t {resources.cpus} \
        -d {input.checkv_db}/{params.db_id} >> {log} 2>&1 
    else
        checkv end_to_end {output.vs2_dir}/final-viral-combined.fa {output.checkv_dir} \
        -t {resources.cpus} \
        -d {input.checkv_db}/checkv-db-v1.5 >> {log} 2>&1    
    fi
    """

rule multiqc:
  input:
    nanoplot_raw_dir  = expand("01.pre-processing/read_qc/{sample}/raw_read_qc", sample = SAMPLES),
    nanoplot_filt_dir = expand("01.pre-processing/read_qc/{sample}/filt_read_qc", sample = SAMPLES),
    qualimap_dir = expand("03.post-processing/mapping_evaluation/{sample}", sample = SAMPLES),
    checkm_dir = expand("03.post-processing/completeness_evaluation/{sample}", sample = SAMPLES),
    gtdbtk_dir = expand("04.taxonomy/{sample}", sample = SAMPLES),
    bakta_dir = expand("05.annotation/bakta/{sample}", sample = SAMPLES)
  output:
    report_html = "09.report/multiqc_report.html",
    multiqc_dir = directory("09.report"),
    multiqc_yaml = "09.report/multiqc_config.yaml"
  conda:
    "envs/multiqc.yaml"
  message:
    "--- MultiQC: Aggregate results. ---"
  log:
    "logs/multiqc.log"
  shell:
    r"""
    set -euo pipefail

    mkdir -p {output.multiqc_dir}

    printf "%s\n" "show_analysis_paths: False" "show_analysis_time: False" > {output.multiqc_yaml}

    cat >> {output.multiqc_yaml} << 'EOF'
sample_names_replace_regex: true
sample_names_replace_exact: true

sample_names_replace:
  '^01\.pre-processing \| read_qc \| ([^|]+) \| filt_read_qc \| \1$': 'filtered read QC | \1'
  '^01\.pre-processing \| read_qc \| ([^|]+) \| raw_read_qc \| \1$':  'raw read QC | \1'

  '^03\.post-processing \| mapping_evaluation \| ([^|]+) \| \1_map$': 'map QC pt.1 | \1'
  '^03\.post-processing \| mapping_evaluation \| ([^|]+) \| raw_data$': 'map QC pt.2 | \1'

  '^05\.annotation \| bakta \| ([^|]+) \| \1$': 'annotation | \1'
EOF

    IGNORE_ARG=""
    if find {input.nanoplot_raw_dir} {input.nanoplot_filt_dir} \
      -type f -name '*NanoStats_post_filtering.txt' -print -quit | grep -q .; then
      IGNORE_ARG="--ignore '*NanoStats_post_filtering.txt'"
    fi

    multiqc \
      $IGNORE_ARG \
      --config {output.multiqc_yaml} \
      -d \
      {input.nanoplot_raw_dir} \
      {input.nanoplot_filt_dir} \
      {input.qualimap_dir} \
      {input.checkm_dir} \
      {input.gtdbtk_dir} \
      {input.bakta_dir} \
      --outdir {output.multiqc_dir} \
      --filename multiqc_report.html > {log} 2>&1
    """